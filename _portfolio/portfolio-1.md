---
title: "Extending text-driven 3D human motion generation with Diffusion Models using LLM paraphrasing"
excerpt: "<img src='/images/portfolio/motiongeneration.png'>"
collection: portfolio
category: Research Projects
---

* __With__: [Mathis Wauquiez](https://github.com/mathis-wauquiez), supervised by [Leore Bensabath](https://imagine-lab.enpc.fr/staff-members/leore-bensabath/)
* __Ressources__: [Slides](/files/portfolio/recvis_fp_slides.pdf); [Report](/files/portfolio/recvis_fp_report.pdf); [Code](https://github.com/MathisWauquiezz/RecVisFP)
* __When__: 2025
* __Associated to__: [MVA](https://www.master-mva.com/)

The project involved creating a text-driven 3D human motion generation model using diffusion models. We studied extensively the generalization capabilities of the model across different datasets, that have different textual description styles. We show that by paraphrasing the text descriptions, we can improve the generalization capabilities of the model. We also explore the impact of different augmentations on the model's performance. Finally, inspired by the success of diffusion models in image generation, we explore the use of ConvUnets with attention mechanisms as the backbone of the model.